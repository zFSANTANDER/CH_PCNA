{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Detección Corte de hoja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook es creado para el entrenamiento de red neuronal para detección de corte de hoja de maquina L2.\n",
    "Es importante que cada vez que se realicen cambios al codigo queden documentados indicando:\n",
    "- Razon de la modificación\n",
    "- Fecha de modificación\n",
    "- Quien ejecuto la modificación\n",
    "\n",
    "Lo que buscamos con utilizar este notebook es que todos podamos documentar y aportar en la creación del modelo.\n",
    "Los integrantes del equipo de trabajo son:\n",
    "- Leonardo Bravo\n",
    "- Victor Encina\n",
    "- Yamil Avello\n",
    "- Guillermo Viñas\n",
    "- Felipe Santander\n",
    "\n",
    "El Notebook fue creado el 10.09.2019.\n",
    "\n",
    "1-. Instalado modulo de TensorFlow (10.09.2019)\n",
    "\n",
    "**Felipe Santander** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalación de SW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /srv/conda/lib/python3.6/site-packages (1.14.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /srv/conda/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /srv/conda/lib/python3.6/site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /srv/conda/lib/python3.6/site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /srv/conda/lib/python3.6/site-packages (from tensorflow) (1.16.3)\n",
      "Requirement already satisfied: wheel>=0.26 in /srv/conda/lib/python3.6/site-packages (from tensorflow) (0.33.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in /srv/conda/lib/python3.6/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /srv/conda/lib/python3.6/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /srv/conda/lib/python3.6/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /srv/conda/lib/python3.6/site-packages (from tensorflow) (0.8.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /srv/conda/lib/python3.6/site-packages (from tensorflow) (0.1.7)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /srv/conda/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /srv/conda/lib/python3.6/site-packages (from tensorflow) (1.24.0)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /srv/conda/lib/python3.6/site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /srv/conda/lib/python3.6/site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /srv/conda/lib/python3.6/site-packages (from tensorflow) (0.8.0)\n",
      "Requirement already satisfied: setuptools in /srv/conda/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow) (41.2.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /srv/conda/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /srv/conda/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: h5py in /srv/conda/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow) (2.10.0)\n",
      "Requirement already satisfied: pandas in /srv/conda/lib/python3.6/site-packages (0.24.2)\n",
      "Requirement already satisfied: pytz>=2011k in /srv/conda/lib/python3.6/site-packages (from pandas) (2019.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /srv/conda/lib/python3.6/site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /srv/conda/lib/python3.6/site-packages (from pandas) (1.16.3)\n",
      "Requirement already satisfied: six>=1.5 in /srv/conda/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "#IMPORTANTE: Instalar tensorflow y pandas al correr por primera vez notebook\n",
    "!pip install tensorflow\n",
    "#!conda install pandas\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importación \n",
    "### 1.1 Importación de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "pd.__version__\n",
    "from tensorflow.python.framework import ops\n",
    "#from tf_utils import load_dataset, random_mini_batches, convert_to_one_hot, predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Importación de datasets\n",
    "Se importan los datasets previamente rescatados, estos deben ser guardados en la carpeta raiz de notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La dimension de set de entrenamiento es X:  (53, 5580)\n",
      "La dimension de set de entrenamiento es Y:  (1, 5580)\n",
      "620.0\n",
      "X_max:  [[620.]]\n",
      "X_min:  [[570.]]\n",
      "97.6230009859033\n",
      "(53, 1)\n"
     ]
    }
   ],
   "source": [
    "#Cargar datasets para entrenamiento\n",
    "#print(os.getcwd())\n",
    "#print(os.listdir())\n",
    "X_mean=[]\n",
    "X_Train = pd.read_csv('/home/jovyan/binder/X_Train_2018.csv',delimiter=';',engine='python')\n",
    "Y_Train = pd.read_csv('/home/jovyan/binder/Y_Train_2018.csv',delimiter=';',engine='python')\n",
    "#print(np.sum(X_Train.isnull()))\n",
    "X_Train=X_Train.values.T\n",
    "Y_Train=Y_Train.values.T\n",
    "X_Train=X_Train.astype(np.float)\n",
    "Y_Train=Y_Train.astype(np.float)\n",
    "X_max=np.zeros((X_Train.shape[0],1))\n",
    "X_min=np.zeros((X_Train.shape[0],1))\n",
    "print(\"La dimension de set de entrenamiento es X: \",X_Train.shape)\n",
    "print(\"La dimension de set de entrenamiento es Y: \",Y_Train.shape)\n",
    "#print(data[data.HOJA == 'CORTE'])\n",
    "i=0\n",
    "\n",
    "mean=np.reshape(np.mean(X_Train,axis=1),(53,1),order='F')\n",
    "var=np.reshape(np.var(X_Train,axis=1),(53,1),order='F')\n",
    "devstd=np.reshape(np.std(X_Train,axis=1),(53,1),order='F')\n",
    "cont=X_Train.shape[0]\n",
    "for i in range(cont):\n",
    "        X_max[i]=np.max(X_Train[[i]])\n",
    "        X_min[i]=np.min(X_Train[[i]])\n",
    "X_gain=X_max-X_min\n",
    "X_train_norm=np.divide(X_Train-X_min,X_gain)\n",
    "X_train_std=np.divide((X_Train-mean),devstd)\n",
    "#X_max[52]=np.max(X_Train[[52]])\n",
    "print(np.max(X_Train[[52]]))\n",
    "print(\"X_max: \",X_max[[52]])\n",
    "print(\"X_min: \",X_min[[52]])\n",
    "\n",
    "print(np.mean(X_Train))\n",
    "print(devstd.shape)\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Creación de Minibatch\n",
    "Para acelerar los entrenamientos se crean sets de datos mas pequeños de forma que no es necesario explorar el sets de datos completos para obtener una aproximacion de las matrices de pesos y bias, y a cada exploracion de minibatch se obtiene una optimización de los parametros de la red neuronal.\n",
    "El ideal es que los tamaños de los minibatches sea de numero par consistentes con cuentas binarias (32,64,128,512...) de manera de optimizar el tamaño de uso de memoria RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobación de correcto funcionamiento de función\n",
    "\n",
    "```Random_mini_batches(X_{}train,Y_{}Train,32,1)```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the 1st mini_batch_X: (53, 32)\n",
      "shape of the 2nd mini_batch_X: (53, 32)\n",
      "shape of the 3rd mini_batch_X: (53, 32)\n",
      "shape of the 1st mini_batch_Y: (1, 32)\n",
      "shape of the 2nd mini_batch_Y: (1, 32)\n",
      "shape of the 3rd mini_batch_Y: (1, 32)\n",
      "mini batch check: [1.19762304 1.19976401 1.2003721 ]\n"
     ]
    }
   ],
   "source": [
    "mini_batches = random_mini_batches(X_Train, Y_Train,32,1)\n",
    "print (\"shape of the 1st mini_batch_X: \" + str(mini_batches[0][0].shape))\n",
    "print (\"shape of the 2nd mini_batch_X: \" + str(mini_batches[1][0].shape))\n",
    "print (\"shape of the 3rd mini_batch_X: \" + str(mini_batches[2][0].shape))\n",
    "print (\"shape of the 1st mini_batch_Y: \" + str(mini_batches[0][1].shape))\n",
    "print (\"shape of the 2nd mini_batch_Y: \" + str(mini_batches[1][1].shape)) \n",
    "print (\"shape of the 3rd mini_batch_Y: \" + str(mini_batches[2][1].shape))\n",
    "print (\"mini batch check: \" + str(mini_batches[0][0][0][0:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creación Red Neuronal\n",
    "\n",
    "### 2.1 Función para creación de vectores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Crea los placeholders para la sesion de tensorflow.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- escalar, tamaño de variables de entradas\n",
    "    n_y -- escalar, numero de calisificadores (caso particular de detección corte de hoja 1)\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder para los datos de entrada, de dimension [n_x, None] y dtype \"float\"\n",
    "    Y -- placeholder para las etiquetas de salida, de dimensión [n_y, None] y dtype \"float\"\n",
    "    \"\"\"\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape=(n_x,None))\n",
    "    Y = tf.placeholder(tf.float32,  shape=(n_y,None))\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Función de inicialización de parametros\n",
    "Se inicializan las matrices de peso y bias de la red neuronal.\n",
    "En este bloque es donde se indica la cantidad de neuronas que tendra cada capa.\n",
    "\n",
    "Inicialmente la cantidad de neuronas en las capas ocultas es la siguiente:\n",
    "\n",
    "* $Capa_1: 15$\n",
    "* $Capa_2: 15$\n",
    "* $Capa_3: 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Inicializa los parametros para crear la red neuronal en tensorflow. Las dimensiones son:\n",
    "                        W1 : [15, 53]\n",
    "                        b1 : [15, 1]\n",
    "                        W2 : [15, 15]\n",
    "                        b2 : [15, 1]\n",
    "                        W3 : [1, 15]\n",
    "                        b3 : [1, 1]\n",
    "    \n",
    "    Salida:\n",
    "    parameters -- dictionario que contiene W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)\n",
    "    W1 =tf.get_variable(\"W1\", [12,53], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [12,1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [1,12], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [1,1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [1,1], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [1,1], initializer = tf.zeros_initializer())\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Función Feedforward\n",
    "\n",
    "Se construye red neuronal con funciones de activación sigmoidales de tres capas:\n",
    "<img src=\"Imagenes/Arquitectura Red.png\">\n",
    "\n",
    "---\n",
    "\n",
    "Matematicamente es:\n",
    "\n",
    "$$Z^{[1]}=W^{[1]}*X_{norm}+B_{[1]}\\small\\tag{1}$$\n",
    "$$Z^{[i]}=W^{[i]}*Z^{[i]}+B_{[i]}\\small\\tag{2}$$\n",
    "$$A^{[i]}=sigmoid(Z^{[i]})=\\sigma(Z^{[i]})\\small\\tag{3}$$\n",
    "$$\\hat{y}=\\sigma(Z^{[3]})\\small\\tag{4}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implementación de forward propagation: LINEAR -> SIGMOID -> LINEAR -> SIGMOID -> LINEAR -> SIGMOID\n",
    "    \n",
    "    Arguments:\n",
    "    X -- entrada dataset placeholder, de dimension (tamaño entrada, numero de muestras)\n",
    "    parameters -- contiene los parametros \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  las dimensiones son dadas por la función de inicialización\n",
    "\n",
    "    Salida:\n",
    "    Z3 -- salida de la ultima función LINEAR\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    Z1 = tf.add(tf.matmul(W1,X),b1)                     # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.sigmoid(Z1)                              # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2,A1),b2)                    # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.sigmoid(Z2)                              # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3,A2),b3)                    # Z3 = np.dot(W3,Z2) + b3\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Función Costo\n",
    "\n",
    "La función de costo utilizada es:\n",
    "$$ J = - \\frac{1}{m}  \\sum_{i = 1}^m  \\large ( \\small y^{(i)} \\log a^{ [2] (i)} + (1-y^{(i)})\\log (1-a^{ [2] (i)} )\\large )\\small\\tag{5}$$\n",
    "La función de costo (5) es conocida como \"*sigmoid cross entropy*\" y en tensorflow puede ser llamada como:\n",
    "\n",
    "```tf.nn.sigmoid_cross_entropy_with_logits()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Calculo costo\n",
    "    \n",
    "    Argumentos:\n",
    "    Z3 -- salida de forward propagation (salida de la ultima función LINEAR), de dimension (1, numero de muestras)\n",
    "    Y -- \"true\" vector de etiquetas placeholder, misma dimension que Z3\n",
    "    \n",
    "    Salida:\n",
    "    cost - Tensor de la función de costo\n",
    "    \"\"\"\n",
    "    \n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Construcción del Modelo\n",
    "Se utilizan las funciones generadas antes para construir el modelo de la red neuronal y generar el entrenamiento utilizando los minibatch ya generados. Los parametros que pueden ser modificados para la busqueda de mejor comportamiento del modelo son los siguientes:\n",
    "* learning rate ```learning_rate```: tamaño de la corrección por cada iteración obtenida desde el algoritmo Adam.\n",
    "* numero de epocas ```num_epochs```: numero de veces que explorará todos los minibatches.\n",
    "* tamaño de minibatch ```minibatch_size```: tamaño de los minibatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.001,\n",
    "          num_epochs = 1500, minibatch_size = 32, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implementa tres-capas tensorflow red neuronal: LINEAR->SIGMOID->LINEAR->SIGMOID->LINEAR->SIGMOID.\n",
    "    \n",
    "    Argumentos:\n",
    "    X_train -- training set, de dimension (tamaño entradas = 53, numero de muestras = 1080)\n",
    "    Y_train -- test set, de dimension (tamaño salida = 1, numero de muestras = 1080)\n",
    "    X_test -- training set, de dimension (tamaño entradas = 53, numero de muestras = 1080)\n",
    "    Y_test -- test set, de dimension (tamaño salida = 1, numero de muestras = 1080)\n",
    "    learning_rate -- learning rate de la optimización\n",
    "    num_epochs -- number de epocas de ciclo de optimización\n",
    "    minibatch_size -- tamaño minibatch\n",
    "    print_cost -- True para imprimir el costo cada 100 epocas\n",
    "    \n",
    "    Salida:\n",
    "    parameters -- parametros aprendidos por el modelos.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    print(\"n_x: \",n_x)\n",
    "    print(\"n_y: \",n_y)\n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    X, Y = create_placeholders(n_x,n_y)\n",
    "\n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters()\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "        \n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                #print(minibatch_X[1][0])\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('costo')\n",
    "        plt.xlabel('iteraciones (x10)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Los parametros han sido entrenados!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        W1 = parameters['W1']\n",
    "        b1 = parameters['b1']\n",
    "        W2 = parameters['W2']\n",
    "        b2 = parameters['b2']\n",
    "        W3 = parameters['W3']\n",
    "        b3 = parameters['b3']\n",
    "        print(\"W1= \", W1)\n",
    "        print(\"b1= \", b1)\n",
    "        print(\"W2= \", W2)\n",
    "        print(\"b2= \", b2)\n",
    "        print(\"W3= \", W3)\n",
    "        print(\"b3= \", b3)\n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Entrenamiento Red Neuronal\n",
    "Se entrena la red neuronal utilizando el set de datos normalizado, como resultado se obtendra:\n",
    "1. Cada 100 epocas imprimira el valor de la función de costo que se esta optimizando\n",
    "2. Al finalizar la iteración por la cantidad de epocas imprimira el grafico de evolución de la función de costo\n",
    "3. Imprimira el valor de cada una de las matrices de pesos y bias de cada capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_x:  53\n",
      "n_y:  1\n",
      "Cost after epoch 0: 0.697182\n",
      "Cost after epoch 100: 0.190844\n",
      "Cost after epoch 200: 0.055989\n",
      "Cost after epoch 300: 0.001940\n",
      "Cost after epoch 400: 0.000434\n",
      "Cost after epoch 500: 0.000265\n",
      "Cost after epoch 600: 0.000369\n",
      "Cost after epoch 700: 0.000098\n",
      "Cost after epoch 800: 0.000082\n",
      "Cost after epoch 900: 0.000048\n",
      "Cost after epoch 1000: 0.000039\n",
      "Cost after epoch 1100: 0.001025\n",
      "Cost after epoch 1200: 0.000022\n",
      "Cost after epoch 1300: 0.000020\n",
      "Cost after epoch 1400: 0.000013\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los parametros han sido entrenados!\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 1.0\n",
      "W1=  [[-3.42181236e-01 -2.36650562e+00 -1.52522421e+00  2.53147650e+00\n",
      "  -2.43298244e+00 -2.07227156e-01  1.32764304e+00 -8.26530039e-01\n",
      "  -9.66910899e-01 -1.23200691e+00 -2.39561200e-01  8.89840961e-01\n",
      "  -1.90254956e-01  4.12995458e-01  8.70431602e-01  4.87489551e-01\n",
      "  -9.98514831e-01  4.02838551e-03 -9.87440705e-01 -6.21627390e-01\n",
      "   1.85607088e+00 -2.69471049e-01  6.11742854e-01 -1.31722778e-01\n",
      "  -1.49259567e+00 -9.40663576e-01 -1.18373489e+00 -1.19176543e+00\n",
      "   7.05419540e-01  2.10014439e+00  2.04573202e+00  6.41279578e-01\n",
      "  -5.91166615e-01  1.12545264e+00 -1.52100354e-01  6.62391067e-01\n",
      "  -1.82689977e+00 -7.48914540e-01  9.51008081e-01 -1.13089681e+00\n",
      "   7.22433090e-01 -5.76902211e-01 -2.37300888e-01 -1.36245644e+00\n",
      "   5.95313132e-01  5.68136811e-01  1.68027356e-01 -2.67158411e-02\n",
      "   7.64291361e-02 -9.75588784e-02 -1.27617335e+00 -5.69141209e-01\n",
      "  -1.42813504e-01]\n",
      " [-1.78061593e+00 -2.75454116e+00  2.14725494e+00 -1.05187678e+00\n",
      "   3.97247255e-01  7.72229552e-01  3.57984424e+00 -6.61933124e-01\n",
      "  -2.97471905e+00 -3.61293592e-02 -5.86206555e-01 -1.28365338e+00\n",
      "  -1.63406062e+00 -7.87842393e-01 -1.14236319e+00 -1.22513676e+00\n",
      "  -6.76851511e-01  6.56600595e-01 -1.20197022e+00 -7.40236938e-02\n",
      "  -6.22560322e-01 -6.99860096e-01  6.22612000e-01 -3.26200753e-01\n",
      "  -1.62574887e+00  1.36475003e+00  3.07934463e-01  1.32156932e+00\n",
      "   7.95215726e-01 -5.49877584e-01  1.21527958e+00 -6.19232535e-01\n",
      "   1.70632973e-01  2.19850731e+00 -1.25141513e+00  4.43970472e-01\n",
      "  -4.18614224e-02  2.38287497e+00 -2.60183477e+00 -4.29933637e-01\n",
      "   1.71919274e+00 -6.93692088e-01 -8.51239115e-02 -8.43543947e-01\n",
      "  -4.63921219e-01  2.46348679e-01 -8.57239544e-01 -2.83587039e-01\n",
      "  -1.68486083e+00 -1.42794120e+00 -2.22634912e+00 -1.43156087e+00\n",
      "   2.48120546e+00]\n",
      " [ 1.79090035e+00 -7.63478184e+00 -5.66885090e+00 -7.41531277e+00\n",
      "   6.67658567e-01 -4.25900555e+00  3.96359396e+00  5.18693876e+00\n",
      "   4.76825619e+00 -3.10355842e-01 -2.30918217e+00 -2.78099084e+00\n",
      "  -2.16424417e+00  1.12771916e+00  6.66138935e+00  1.52861154e+00\n",
      "  -1.66634738e+00  2.49778795e+00 -1.19615602e+00  3.35964537e+00\n",
      "   2.99495769e+00 -3.34637308e+00  1.09503186e+00 -7.29867965e-02\n",
      "  -6.59245110e+00  2.42624235e+00 -2.90875673e+00 -1.57973123e+00\n",
      "   4.02571249e+00 -3.37661684e-01  5.00912380e+00 -9.49538171e-01\n",
      "  -6.22119761e+00 -4.13150978e+00  3.05748439e+00 -2.34399414e+00\n",
      "  -3.81652284e+00  2.84387064e+00  5.94083428e-01  5.32915354e+00\n",
      "  -3.03079247e+00  1.35225320e+00  4.51791674e-01 -3.27348304e+00\n",
      "  -3.13255310e+00  2.13484168e+00  6.39773846e-01 -5.68437433e+00\n",
      "   6.83522999e-01 -7.47964799e-01 -6.48338652e+00 -2.63489127e+00\n",
      "   3.84628129e+00]\n",
      " [-1.94254243e+00 -3.20081139e+00 -2.69203854e+00  2.22829843e+00\n",
      "  -9.75928962e-01 -4.06695426e-01 -9.39865559e-02 -7.43399203e-01\n",
      "   3.17315981e-02 -8.49759996e-01  4.45604563e-01  4.22667563e-01\n",
      "  -2.24985981e+00  7.82202929e-02 -1.11648738e+00  1.23658216e+00\n",
      "  -6.29904222e+00 -4.99409199e-01 -1.21182013e+00 -1.41119218e+00\n",
      "   1.27071393e+00 -1.26261783e+00  3.72498073e-02 -9.43879485e-01\n",
      "  -1.66096544e+00  5.21761291e-02 -5.95342159e-01  5.07788539e-01\n",
      "   8.08399796e-01 -6.88622415e-01 -7.62255490e-02  1.23800123e+00\n",
      "  -7.77029812e-01  1.23395443e-01  1.37817398e-01  3.02174592e+00\n",
      "  -9.30341065e-01 -5.20485878e+00 -4.54082298e+00  5.53054102e-02\n",
      "  -2.11604738e+00 -3.93108130e-01 -1.81509987e-01 -1.78979421e+00\n",
      "   1.98935509e-01  2.86309004e-01  4.05049354e-01 -3.63667421e-02\n",
      "  -2.29447812e-01 -2.15619862e-01 -3.10249162e+00 -2.57521844e+00\n",
      "  -1.97430179e-01]\n",
      " [ 1.97780824e+00  3.19477320e+00  1.00448310e-01  8.71603191e-02\n",
      "   1.12511563e+00  3.00515860e-01 -1.86538661e+00 -4.86719936e-01\n",
      "  -2.72416472e+00  5.30174077e-01 -1.28213859e+00 -1.83522737e+00\n",
      "   1.29164064e+00 -1.42953253e+00 -3.13279718e-01  3.53930026e-01\n",
      "  -1.95348382e-01 -6.24341607e-01  6.95692003e-01  6.02080584e-01\n",
      "   9.07702625e-01 -1.41873583e-01 -6.55388713e-01  5.81014395e-01\n",
      "   1.77405313e-01  6.98341355e-02  3.60459864e-01  5.04241943e-01\n",
      "   1.83587098e+00 -2.83818766e-02  1.87140048e+00 -4.48794305e-01\n",
      "   3.17828506e-01 -5.02827108e-01 -2.79081988e+00 -3.13211036e+00\n",
      "   5.56287587e-01 -1.04544377e+00  9.28501308e-01  6.33743525e-01\n",
      "   1.23472318e-01  8.36960554e-01  8.83794069e-01  1.25114703e+00\n",
      "  -1.71088293e-01 -5.07298470e-01  1.36937380e-01  4.12011594e-01\n",
      "   2.51866244e-02 -4.57336428e-03  6.45130515e-01 -9.56624746e-01\n",
      "  -8.56923580e-01]\n",
      " [ 2.92086649e+00  1.53699045e+01  7.16514111e+00  1.20159826e+01\n",
      "  -4.01005650e+00  9.52519923e-02 -3.61987972e+00  1.44689336e-01\n",
      "   1.35321369e+01  6.71070576e+00  3.37879300e+00 -1.86006701e+00\n",
      "   4.58689594e+00  3.62164068e+00  3.79697919e+00 -1.31124103e+00\n",
      "   2.12918544e+00 -3.86679983e+00 -1.88252807e+00 -1.72746503e+00\n",
      "   3.32758403e+00  5.84349394e-01 -7.82707512e-01 -2.91691709e+00\n",
      "   1.02383919e+01 -2.75423121e+00 -2.73115492e+00 -2.66331935e+00\n",
      "  -8.32957923e-01 -4.69775200e-01 -6.63216639e+00  3.11272311e+00\n",
      "  -1.03885150e+00 -4.11600113e+00  1.35920131e+00  1.75693560e+00\n",
      "   1.28722346e+00 -5.30041218e+00 -1.97319114e+00  4.27146769e+00\n",
      "   1.10593820e+00  1.51573765e+00 -5.75868273e+00  4.23415852e+00\n",
      "   2.39038754e+00 -4.54396200e+00 -2.76237249e-01 -1.38369691e+00\n",
      "  -6.33680582e-01 -8.31202865e-01 -1.33703804e+00  7.54474497e+00\n",
      "  -8.63164711e+00]\n",
      " [ 1.54672647e+00  1.50815463e+00  1.58362293e+00  5.03535122e-02\n",
      "   5.86008608e-01  6.70247674e-01  2.18903378e-01 -1.12459041e-01\n",
      "  -1.48757249e-02  1.04359183e-02 -1.14972544e+00 -1.97019422e+00\n",
      "  -1.49043247e-01 -9.80468929e-01 -5.25986135e-01  3.25651795e-01\n",
      "  -6.87490284e-01 -9.35890019e-01 -3.30763727e-01  3.88208777e-01\n",
      "   6.54334009e-01 -6.31958485e-01  8.66883323e-02 -3.80954742e-01\n",
      "  -5.12890637e-01  4.63875830e-02  4.59982067e-01 -1.04373431e+00\n",
      "   1.57085091e-01  8.35153997e-01 -2.28858218e-01  3.88099670e-01\n",
      "   6.51775077e-02  1.22875810e+00 -1.24131024e+00  6.17946684e-01\n",
      "   1.91593277e+00  2.26359189e-01  1.75201726e+00  5.48698664e-01\n",
      "   3.00403476e-01  2.04163328e-01  2.00763792e-01  1.38592458e+00\n",
      "  -4.03683990e-01 -9.88452733e-01  1.75638616e-01 -6.69770688e-03\n",
      "  -2.58267224e-01 -6.94214106e-01  3.48369884e+00  3.46112043e-01\n",
      "   6.20471120e-01]\n",
      " [ 4.94327068e+00  1.05698118e+01  2.22878003e+00 -2.06719232e+00\n",
      "   1.53427243e+00 -1.00184739e+00 -7.34832335e+00 -2.41548681e+00\n",
      "  -1.89340603e+00  1.87385619e+00 -3.74056745e+00 -6.33821917e+00\n",
      "  -8.75671005e+00 -5.94215631e-01 -5.76100779e+00  4.04607487e+00\n",
      "  -3.62618780e+00 -5.65495157e+00  1.81900775e+00 -4.20115042e+00\n",
      "   1.89071745e-01  4.17421961e+00  1.38759899e+00 -9.43360209e-01\n",
      "   3.04272270e+00 -1.15905380e+00  8.02410793e+00  8.05516338e+00\n",
      "  -3.88466746e-01 -1.97162402e+00  1.51827180e+00 -1.87896407e+00\n",
      "  -4.02833557e+00 -3.17965531e+00 -1.72657475e-01  3.69063973e-01\n",
      "  -1.13197637e+00  2.88029265e+00  3.55281663e+00 -3.06921029e+00\n",
      "   2.62734461e+00 -3.92999196e+00 -1.45954740e+00 -5.58829784e-01\n",
      "  -1.03186691e+00  1.55687466e-01 -1.16601065e-01 -3.74821395e-01\n",
      "   5.13433181e-02 -5.08432984e-01  1.54026842e+00 -5.78591919e+00\n",
      "   8.56998348e+00]\n",
      " [ 1.21065927e+00  1.78211713e+00 -3.40529561e+00  4.78226042e+00\n",
      "  -2.00221086e+00  7.37745464e-01  4.12677288e-01 -1.43236816e+00\n",
      "  -2.47435069e+00 -1.10313165e+00  1.25449872e+00  2.74960697e-01\n",
      "  -1.49951029e+00  6.39400259e-02  1.04766405e+00  3.05440933e-01\n",
      "  -5.82220078e-01  4.95854467e-01  1.20380580e+00 -2.23808616e-01\n",
      "   1.38113034e+00  9.31536257e-01  1.64220929e+00  7.69357622e-01\n",
      "  -9.79173124e-01 -3.52313817e-01 -4.50956970e-02  6.00519300e-01\n",
      "   9.48830545e-01  2.59668112e+00  1.54753566e+00  3.85529935e-01\n",
      "  -1.40425250e-01 -1.23251307e+00 -1.52659559e+00 -9.20656741e-01\n",
      "  -2.29235291e+00  3.19431841e-01 -7.10619092e-01 -6.34700477e-01\n",
      "   3.15875745e+00  5.00043750e-01  8.98832440e-01 -9.02369320e-01\n",
      "   2.19704914e+00  9.47518528e-01  4.19462949e-01  9.22251344e-01\n",
      "  -1.78089654e+00  2.20638084e+00  1.04617167e+00  2.03341460e+00\n",
      "   3.05791259e-01]\n",
      " [ 5.23992014e+00  2.55160732e+01 -2.04533434e+00  2.28415346e+00\n",
      "   4.42283821e+00  2.47530365e+00  8.27402592e+00  2.23782986e-01\n",
      "   3.60458541e+00  9.79754066e+00 -3.46910620e+00  2.67347288e+00\n",
      "   4.15288496e+00  4.13176417e-01 -6.73957920e+00  3.32115126e+00\n",
      "  -3.83418727e+00 -3.02531242e+00 -3.98656815e-01  2.65292168e-01\n",
      "  -1.62612960e-01 -1.33597159e+00 -1.84581470e+00  2.00556844e-01\n",
      "  -1.82860565e+00  1.11849918e+01 -1.07263219e+00 -1.17226732e+00\n",
      "  -1.95833671e+00  2.90518498e+00  2.61742949e+00  2.60952020e+00\n",
      "   8.91198695e-01  1.71418381e+00  4.92277205e-01  2.50678837e-01\n",
      "  -4.55537510e+00 -5.73011255e+00 -9.42200482e-01 -3.41564751e+00\n",
      "   9.44356978e-01 -5.18674803e+00  9.06114280e-01  1.29274297e+00\n",
      "   8.27030361e-01  3.97271961e-01 -7.33608186e-01 -4.67436028e+00\n",
      "  -9.17163908e-01 -9.06042099e-01  2.76131368e+00  1.30001724e+00\n",
      "  -1.88475919e+00]\n",
      " [ 7.81086087e-02 -4.02700520e+00  3.34164023e+00 -1.06080742e+01\n",
      "   7.37092018e+00 -2.24334979e+00  1.29921293e+01  1.28740048e+00\n",
      "   4.31263733e+00  6.45661116e-01 -2.87118554e+00 -1.07168484e+01\n",
      "  -1.97229922e+00  1.58600700e+00  4.26316929e+00 -3.71245337e+00\n",
      "   7.70663023e+00 -5.73449516e+00 -1.54968464e+00  3.24178934e+00\n",
      "   2.88438227e-04 -2.68650556e+00  2.91005087e+00 -3.73449400e-02\n",
      "  -8.12278569e-01 -2.62053251e+00 -1.40802756e-01  3.48154926e+00\n",
      "   1.27240932e+00 -1.19656682e+00  7.78483376e-02 -3.81825328e-01\n",
      "  -4.77930403e+00 -1.94830418e+00  2.38220167e+00 -4.76047945e+00\n",
      "   1.94643825e-01  3.69954515e+00  2.18562293e+00  1.38557100e+00\n",
      "   2.81714767e-01 -8.18526268e-01 -2.92056131e+00 -3.35839081e+00\n",
      "  -1.91236842e+00  4.72280025e-01  2.59493683e-02 -9.57670689e-01\n",
      "  -1.76765651e-01 -3.06978971e-02 -4.88525581e+00 -5.67584801e+00\n",
      "   3.61314082e+00]\n",
      " [ 1.15758419e+00  2.85045004e+00 -3.87718454e-02 -5.23627222e-01\n",
      "   4.30126399e-01 -2.38981223e+00 -3.06089759e-01  5.98388612e-01\n",
      "   6.22062087e-02  1.65176976e+00 -9.42541778e-01 -2.95732856e+00\n",
      "   1.72215521e+00  7.94401228e-01  1.21310818e+00  3.17770720e-01\n",
      "  -3.20335895e-01 -1.46569383e+00 -7.11080730e-01  6.95684373e-01\n",
      "   5.95946932e+00 -8.78668576e-02 -1.59478211e+00 -1.00782239e+00\n",
      "   2.70797396e+00  1.96585789e-01 -5.71146309e-01  5.68616271e-01\n",
      "  -1.63340127e+00 -9.29612577e-01  1.65016437e+00 -3.42685771e+00\n",
      "  -1.01536714e-01  3.58850551e+00 -1.04348564e+00  1.46308351e+00\n",
      "  -5.39673042e+00 -2.86590517e-01 -1.17077255e+00  1.35999334e+00\n",
      "  -2.37641978e+00  4.09121186e-01  3.07270408e+00 -1.06282926e+00\n",
      "  -2.05993080e+00  2.27898622e+00  4.82764930e-01  2.02662992e+00\n",
      "   2.85908192e-01 -2.56254345e-01  5.73200369e+00 -1.12483346e+00\n",
      "  -2.08021259e+00]]\n",
      "b1=  [[-0.11426254]\n",
      " [-0.2811431 ]\n",
      " [ 2.4368086 ]\n",
      " [-0.59043735]\n",
      " [-0.31506112]\n",
      " [-1.6902864 ]\n",
      " [-0.14605461]\n",
      " [ 0.73881155]\n",
      " [ 0.9488807 ]\n",
      " [ 3.3300054 ]\n",
      " [-1.7700393 ]\n",
      " [-0.4535009 ]]\n",
      "W2=  [[-2.4420285 -1.1506282 -1.2074636 -2.4184906  7.264558   5.663358\n",
      "   5.4001164 -3.4220386 -5.3834467 -2.5180278 -4.079555  -4.9417357]]\n",
      "b2=  [[3.9507406]]\n",
      "W3=  [[-26.46488]]\n",
      "b3=  [[12.081979]]\n"
     ]
    }
   ],
   "source": [
    "#parameters = model(X_train_norm, Y_Train, X_train_norm, Y_Train)\n",
    "parameters = model(X_train_std, Y_Train, X_train_std, Y_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
