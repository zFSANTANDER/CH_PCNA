{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"Logo Arauco 1.png\" style=\"width: 100px\">\n",
    "<img align=\"left\" src=\"Logo Arauco 2.png\" style=\"width: 100px\">\n",
    "\n",
    "   #     Notebook Detección Corte de hoja\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook es creado para el entrenamiento de red neuronal para detección de corte de hoja de maquina L2.\n",
    "Es importante que cada vez que se realicen cambios al codigo queden documentados indicando:\n",
    "- Razon de la modificación\n",
    "- Fecha de modificación\n",
    "- Quien ejecuto la modificación\n",
    "\n",
    "Lo que buscamos con utilizar este notebook es que todos podamos documentar y aportar en la creación del modelo.\n",
    "Los integrantes del equipo de trabajo son:\n",
    "- Leonardo Bravo\n",
    "- Victor Encina\n",
    "- Yamil Avello\n",
    "- Guillermo Viñas\n",
    "- Felipe Santander\n",
    "\n",
    "El Notebook fue creado el 10.09.2019.\n",
    "\n",
    "1-. Instalado modulo de TensorFlow (10.09.2019)\n",
    "\n",
    "**Felipe Santander** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalación de SW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /srv/conda/envs/notebook/lib/python3.7/site-packages (19.2.3)\n",
      "Requirement already satisfied: jupyter in /srv/conda/envs/notebook/lib/python3.7/site-packages (1.0.0)\n",
      "Requirement already satisfied: nbconvert in /srv/conda/envs/notebook/lib/python3.7/site-packages (from jupyter) (5.4.1)\n",
      "Requirement already satisfied: qtconsole in /srv/conda/envs/notebook/lib/python3.7/site-packages (from jupyter) (4.5.5)\n",
      "Requirement already satisfied: notebook in /srv/conda/envs/notebook/lib/python3.7/site-packages (from jupyter) (5.7.8)\n",
      "Requirement already satisfied: ipywidgets in /srv/conda/envs/notebook/lib/python3.7/site-packages (from jupyter) (7.4.2)\n",
      "Requirement already satisfied: ipykernel in /srv/conda/envs/notebook/lib/python3.7/site-packages (from jupyter) (5.1.2)\n",
      "Requirement already satisfied: jupyter-console in /srv/conda/envs/notebook/lib/python3.7/site-packages (from jupyter) (6.0.0)\n",
      "Requirement already satisfied: mistune>=0.8.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nbconvert->jupyter) (0.8.4)\n",
      "Requirement already satisfied: jinja2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nbconvert->jupyter) (2.10.1)\n",
      "Requirement already satisfied: pygments in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nbconvert->jupyter) (2.4.2)\n",
      "Requirement already satisfied: traitlets>=4.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nbconvert->jupyter) (4.3.2)\n",
      "Requirement already satisfied: jupyter_core in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nbconvert->jupyter) (4.4.0)\n",
      "Requirement already satisfied: nbformat>=4.4 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nbconvert->jupyter) (4.4.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nbconvert->jupyter) (0.3)\n",
      "Requirement already satisfied: bleach in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nbconvert->jupyter) (3.1.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nbconvert->jupyter) (1.4.2)\n",
      "Requirement already satisfied: testpath in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nbconvert->jupyter) (0.4.2)\n",
      "Requirement already satisfied: defusedxml in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nbconvert->jupyter) (0.5.0)\n",
      "Requirement already satisfied: ipython-genutils in /srv/conda/envs/notebook/lib/python3.7/site-packages (from qtconsole->jupyter) (0.2.0)\n",
      "Requirement already satisfied: jupyter-client>=4.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from qtconsole->jupyter) (5.3.1)\n",
      "Requirement already satisfied: Send2Trash in /srv/conda/envs/notebook/lib/python3.7/site-packages (from notebook->jupyter) (1.5.0)\n",
      "Requirement already satisfied: tornado<7,>=4.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from notebook->jupyter) (6.0.3)\n",
      "Requirement already satisfied: pyzmq>=17 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from notebook->jupyter) (18.1.0)\n",
      "Requirement already satisfied: prometheus-client in /srv/conda/envs/notebook/lib/python3.7/site-packages (from notebook->jupyter) (0.7.1)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from notebook->jupyter) (0.8.2)\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /srv/conda/envs/notebook/lib/python3.7/site-packages (from ipywidgets->jupyter) (7.8.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.4.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from ipywidgets->jupyter) (3.4.2)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from jupyter-console->jupyter) (2.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from jinja2->nbconvert->jupyter) (1.1.1)\n",
      "Requirement already satisfied: six in /srv/conda/envs/notebook/lib/python3.7/site-packages (from traitlets>=4.2->nbconvert->jupyter) (1.12.0)\n",
      "Requirement already satisfied: decorator in /srv/conda/envs/notebook/lib/python3.7/site-packages (from traitlets>=4.2->nbconvert->jupyter) (4.4.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nbformat>=4.4->nbconvert->jupyter) (3.0.2)\n",
      "Requirement already satisfied: webencodings in /srv/conda/envs/notebook/lib/python3.7/site-packages (from bleach->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from jupyter-client>=4.1->qtconsole->jupyter) (2.8.0)\n",
      "Requirement already satisfied: backcall in /srv/conda/envs/notebook/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter) (0.1.0)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /srv/conda/envs/notebook/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter) (4.7.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter) (41.2.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter) (0.15.1)\n",
      "Requirement already satisfied: pickleshare in /srv/conda/envs/notebook/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter) (0.7.5)\n",
      "Requirement already satisfied: wcwidth in /srv/conda/envs/notebook/lib/python3.7/site-packages (from prompt-toolkit<2.1.0,>=2.0.0->jupyter-console->jupyter) (0.1.7)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (0.15.4)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (19.1.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter) (0.6.0)\n",
      "Requirement already satisfied: parso>=0.5.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from jedi>=0.10->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter) (0.5.1)\n",
      "Requirement already satisfied: tensorflow==1.14 in /srv/conda/envs/notebook/lib/python3.7/site-packages (1.14.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow==1.14) (0.8.0)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow==1.14) (1.14.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow==1.14) (1.17.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow==1.14) (1.1.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow==1.14) (1.12.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow==1.14) (3.9.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow==1.14) (0.1.7)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow==1.14) (1.0.8)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow==1.14) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow==1.14) (0.33.6)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow==1.14) (1.24.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow==1.14) (1.11.2)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow==1.14) (1.14.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow==1.14) (0.8.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow==1.14) (0.2.2)\n",
      "Requirement already satisfied: setuptools in /srv/conda/envs/notebook/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow==1.14) (41.2.0)\n",
      "Requirement already satisfied: h5py in /srv/conda/envs/notebook/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: markdown>=2.6.8 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (0.16.0)\n",
      "Requirement already satisfied: pandas in /srv/conda/envs/notebook/lib/python3.7/site-packages (0.25.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (2019.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (1.17.2)\n",
      "Requirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
      "Requirement already satisfied: matplotlib in /srv/conda/envs/notebook/lib/python3.7/site-packages (3.1.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib) (1.17.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /srv/conda/envs/notebook/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (41.2.0)\n"
     ]
    }
   ],
   "source": [
    "#IMPORTANTE: Instalar tensorflow y pandas al correr por primera vez notebook\n",
    "!pip install --upgrade pip\n",
    "!pip install jupyter\n",
    "!pip install tensorflow==1.14\n",
    "#!conda install pandas\n",
    "!pip install pandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importación \n",
    "### 1.1 Importación de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "print(tf.__version__)\n",
    "from tensorflow.python.framework import ops\n",
    "#from tf_utils import load_dataset, random_mini_batches, convert_to_one_hot, predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Importación de datasets\n",
    "Se importan los datasets previamente rescatados, estos deben ser guardados en la carpeta raiz de notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La dimension de set de entrenamiento es X:  (53, 5580)\n",
      "La dimension de set de entrenamiento es Y:  (1, 5580)\n"
     ]
    }
   ],
   "source": [
    "#Cargar datasets para entrenamiento\n",
    "#print(os.getcwd())\n",
    "#print(os.listdir())\n",
    "X_mean=[]\n",
    "X_Train = pd.read_csv('/home/jovyan/X_Train_2018.csv',delimiter=';',engine='python')\n",
    "Y_Train = pd.read_csv('/home/jovyan/Y_Train_2018.csv',delimiter=';',engine='python')\n",
    "#print(np.sum(X_Train.isnull()))\n",
    "X_Train=X_Train.values.T\n",
    "Y_Train=Y_Train.values.T\n",
    "X_Train=X_Train.astype(np.float)\n",
    "Y_Train=Y_Train.astype(np.float)\n",
    "print(\"La dimension de set de entrenamiento es X: \",X_Train.shape)\n",
    "print(\"La dimension de set de entrenamiento es Y: \",Y_Train.shape)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Normalización set de datos\n",
    "La normalización de datos tiene por objetivo normalizar a por unidad todos los datos de entrada, es decir en rango de $[0,1]$ para extraer efectivamente la información de cada una de las variables alimentada al modelo.\n",
    "\n",
    "Para la normalización de las variables se utilizaron dos formas:\n",
    "1. Normalización de datos:\n",
    "$$X_{norm}=\\frac{(X-X_{Min})}{(X_{Max}-X_{Min})}\\tag{1}$$\n",
    "2. Estandarización de datos\n",
    "$$X_{std}=\\frac{(X-\\bar{X})}{\\sigma}\\tag{2}$$\n",
    " (Desviación estandar): $ \\sigma = \\sqrt[]{\\frac{1}{N-1}\\sum_{i=1}^{N}X_i-\\bar{X}}\\tag{3}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La dimension de los datos originales es (53, 5580)\n",
      "La dimension de los datos normalizados es (53, 5580)\n",
      "La dimension de los datos estandarizados es (53, 5580)\n"
     ]
    }
   ],
   "source": [
    "X_max=np.zeros((X_Train.shape[0],1))\n",
    "X_min=np.zeros((X_Train.shape[0],1))\n",
    "\n",
    "#print(data[data.HOJA == 'CORTE'])\n",
    "i=0\n",
    "\n",
    "mean=np.reshape(np.mean(X_Train,axis=1),(53,1),order='F')\n",
    "var=np.reshape(np.var(X_Train,axis=1),(53,1),order='F')\n",
    "devstd=np.reshape(np.std(X_Train,axis=1),(53,1),order='F')\n",
    "cont=X_Train.shape[0]\n",
    "for i in range(cont):\n",
    "        X_max[i]=np.max(X_Train[[i]])\n",
    "        X_min[i]=np.min(X_Train[[i]])\n",
    "X_gain=X_max-X_min\n",
    "X_train_norm=np.divide(X_Train-X_min,X_gain)\n",
    "X_train_std=np.divide((X_Train-mean),devstd)\n",
    "#X_max[52]=np.max(X_Train[[52]])\n",
    "#print(np.max(X_Train[[52]]))\n",
    "#print(np.min(X_Train[[52]]))\n",
    "#print(\"X_max: \",X_max[[52]])\n",
    "#print(\"X_min: \",X_min[[52]])\n",
    "\n",
    "print(\"La dimension de los datos originales es\",X_Train.shape)\n",
    "print(\"La dimension de los datos normalizados es\",X_train_norm.shape)\n",
    "print(\"La dimension de los datos estandarizados es\",X_train_std.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Creación de Minibatch\n",
    "Para acelerar los entrenamientos se crean sets de datos mas pequeños de forma que no es necesario explorar el sets de datos completos para obtener una aproximacion de las matrices de pesos y bias, y a cada exploracion de minibatch se obtiene una optimización de los parametros de la red neuronal.\n",
    "El ideal es que los tamaños de los minibatches sea de numero par consistentes con cuentas binarias (32,64,128,512...) de manera de optimizar el tamaño de uso de memoria RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobación de correcto funcionamiento de función\n",
    "\n",
    "```Random_mini_batches(X_{}train,Y_{}Train,32,1)```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the 1st mini_batch_X: (53, 32)\n",
      "shape of the 2nd mini_batch_X: (53, 32)\n",
      "shape of the 3rd mini_batch_X: (53, 32)\n",
      "shape of the 1st mini_batch_Y: (1, 32)\n",
      "shape of the 2nd mini_batch_Y: (1, 32)\n",
      "shape of the 3rd mini_batch_Y: (1, 32)\n",
      "mini batch check: [1.19762304 1.19976401 1.2003721 ]\n"
     ]
    }
   ],
   "source": [
    "mini_batches = random_mini_batches(X_Train, Y_Train,32,1)\n",
    "print (\"shape of the 1st mini_batch_X: \" + str(mini_batches[0][0].shape))\n",
    "print (\"shape of the 2nd mini_batch_X: \" + str(mini_batches[1][0].shape))\n",
    "print (\"shape of the 3rd mini_batch_X: \" + str(mini_batches[2][0].shape))\n",
    "print (\"shape of the 1st mini_batch_Y: \" + str(mini_batches[0][1].shape))\n",
    "print (\"shape of the 2nd mini_batch_Y: \" + str(mini_batches[1][1].shape)) \n",
    "print (\"shape of the 3rd mini_batch_Y: \" + str(mini_batches[2][1].shape))\n",
    "print (\"mini batch check: \" + str(mini_batches[0][0][0][0:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creación Red Neuronal\n",
    "\n",
    "### 2.1 Función para creación de vectores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Crea los placeholders para la sesion de tensorflow.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- escalar, tamaño de variables de entradas\n",
    "    n_y -- escalar, numero de calisificadores (caso particular de detección corte de hoja 1)\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder para los datos de entrada, de dimension [n_x, None] y dtype \"float\"\n",
    "    Y -- placeholder para las etiquetas de salida, de dimensión [n_y, None] y dtype \"float\"\n",
    "    \"\"\"\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape=(n_x,None))\n",
    "    Y = tf.placeholder(tf.float32,  shape=(n_y,None))\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Función de inicialización de parametros\n",
    "Se inicializan las matrices de peso y bias de la red neuronal.\n",
    "En este bloque es donde se indica la cantidad de neuronas que tendra cada capa.\n",
    "\n",
    "Inicialmente la cantidad de neuronas en las capas ocultas es la siguiente:\n",
    "\n",
    "* $Capa_1: 15$\n",
    "* $Capa_2: 15$\n",
    "* $Capa_3: 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Inicializa los parametros para crear la red neuronal en tensorflow. Las dimensiones son:\n",
    "                        W1 : [15, 53]\n",
    "                        b1 : [15, 1]\n",
    "                        W2 : [15, 15]\n",
    "                        b2 : [15, 1]\n",
    "                        W3 : [1, 15]\n",
    "                        b3 : [1, 1]\n",
    "    \n",
    "    Salida:\n",
    "    parameters -- dictionario que contiene W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)\n",
    "    W1 =tf.get_variable(\"W1\", [15,53], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [15,1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [6,15], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [6,1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [1,6], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [1,1], initializer = tf.zeros_initializer())\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Función Feedforward\n",
    "\n",
    "Se construye red neuronal con funciones de activación sigmoidales de tres capas:\n",
    "<img src=\"Arquitectura Red.png\">\n",
    "\n",
    "---\n",
    "\n",
    "Matematicamente es:\n",
    "\n",
    "$$Z^{[1]}=W^{[1]}*X_{norm}+B_{[1]}\\small\\tag{1}$$\n",
    "$$Z^{[i]}=W^{[i]}*Z^{[i]}+B_{[i]}\\small\\tag{2}$$\n",
    "$$A^{[i]}=sigmoid(Z^{[i]})=\\sigma(Z^{[i]})\\small\\tag{3}$$\n",
    "$$\\hat{y}=\\sigma(Z^{[3]})\\small\\tag{4}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implementación de forward propagation: LINEAR -> SIGMOID -> LINEAR -> SIGMOID -> LINEAR -> SIGMOID\n",
    "    \n",
    "    Arguments:\n",
    "    X -- entrada dataset placeholder, de dimension (tamaño entrada, numero de muestras)\n",
    "    parameters -- contiene los parametros \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  las dimensiones son dadas por la función de inicialización\n",
    "\n",
    "    Salida:\n",
    "    Z3 -- salida de la ultima función LINEAR\n",
    "    \"\"\"\n",
    "    \n",
    "    # Rescata los parametros desde el diccionario \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    Z1 = tf.add(tf.matmul(W1,X),b1)\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2,A1),b2)\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3,A2),b3)\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Función Costo\n",
    "\n",
    "La función de costo utilizada es:\n",
    "$$ J = - \\frac{1}{m}  \\sum_{i = 1}^m  \\large ( \\small y^{(i)} \\log a^{ [2] (i)} + (1-y^{(i)})\\log (1-a^{ [2] (i)} )\\large )\\small\\tag{5}$$\n",
    "La función de costo (5) es conocida como \"*sigmoid cross entropy*\" y en tensorflow puede ser llamada como:\n",
    "\n",
    "```tf.nn.sigmoid_cross_entropy_with_logits()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Calculo costo\n",
    "    \n",
    "    Argumentos:\n",
    "    Z3 -- salida de forward propagation (salida de la ultima función LINEAR), de dimension (1, numero de muestras)\n",
    "    Y -- \"true\" vector de etiquetas placeholder, misma dimension que Z3\n",
    "    \n",
    "    Salida:\n",
    "    cost - Tensor de la función de costo\n",
    "    \"\"\"\n",
    "    \n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Construcción del Modelo\n",
    "Se utilizan las funciones generadas antes para construir el modelo de la red neuronal y generar el entrenamiento utilizando los minibatch ya generados. Los parametros que pueden ser modificados para la busqueda de mejor comportamiento del modelo son los siguientes:\n",
    "* learning rate ```learning_rate```: tamaño de la corrección por cada iteración obtenida desde el algoritmo Adam.\n",
    "* numero de epocas ```num_epochs```: numero de veces que explorará todos los minibatches.\n",
    "* tamaño de minibatch ```minibatch_size```: tamaño de los minibatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.001,\n",
    "          num_epochs = 1500, minibatch_size = 32, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implementa tres-capas tensorflow red neuronal: LINEAR->SIGMOID->LINEAR->SIGMOID->LINEAR->SIGMOID.\n",
    "    \n",
    "    Argumentos:\n",
    "    X_train -- training set, de dimension (tamaño entradas = 53, numero de muestras = 1080)\n",
    "    Y_train -- test set, de dimension (tamaño salida = 1, numero de muestras = 1080)\n",
    "    X_test -- training set, de dimension (tamaño entradas = 53, numero de muestras = 1080)\n",
    "    Y_test -- test set, de dimension (tamaño salida = 1, numero de muestras = 1080)\n",
    "    learning_rate -- learning rate de la optimización\n",
    "    num_epochs -- number de epocas de ciclo de optimización\n",
    "    minibatch_size -- tamaño minibatch\n",
    "    print_cost -- True para imprimir el costo cada 100 epocas\n",
    "    \n",
    "    Salida:\n",
    "    parameters -- parametros aprendidos por el modelos.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # para correr modelo sin sobreescribir tf variables\n",
    "    tf.set_random_seed(1)                             # para mantener resultados consistentes\n",
    "    seed = 3                                          # para mantener resultados consistentes\n",
    "    (n_x, m) = X_train.shape                          # (n_x: tamaño set entradas, m : numeros de muestras en el dataset)\n",
    "    n_y = Y_train.shape[0]                            # n_y : tamaño de salida\n",
    "    costs = []                                        # para mantener seguimiento de función de costo\n",
    "    print(\"n_x: \",n_x)\n",
    "    print(\"n_y: \",n_y)\n",
    "    # Crea variables de tf de orden (n_x, n_y)\n",
    "    X, Y = create_placeholders(n_x,n_y)\n",
    "\n",
    "    # Inicializa parametros\n",
    "    parameters = initialize_parameters()\n",
    "    \n",
    "    # Forward propagation: construye forward propagation en el grafico de tensorflow\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    \n",
    "    # Función de costo: Incluye la función de costo en el grafico de tensorflow\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    \n",
    "    # Backpropagation: Define el optimizador de tensorflow. Usa AdamOptimizer.\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    \n",
    "    # Inicializa todas las variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Inicia la sesión para computar el grafico de tensorflow\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Corre initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Realiza training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "        \n",
    "                # Selecciona minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                #print(minibatch_X[1][0])\n",
    "                \n",
    "                #IMPORTANTE: Función que ejecuta optimización en tensorflow\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Muestra el costo en cada epoca\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # grafica el costo\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('costo')\n",
    "        plt.xlabel('iteraciones (x10)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # Guarda los parametros en una variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Los parametros han sido entrenados!\")\n",
    "\n",
    "        # Calcula las predicciones correctas\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "        # Calcula el accuracy en el test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        W1 = parameters['W1']\n",
    "        b1 = parameters['b1']\n",
    "        W2 = parameters['W2']\n",
    "        b2 = parameters['b2']\n",
    "        W3 = parameters['W3']\n",
    "        b3 = parameters['b3']\n",
    "        print(\"W1= \", W1)\n",
    "        print(\"b1= \", b1)\n",
    "        print(\"W2= \", W2)\n",
    "        print(\"b2= \", b2)\n",
    "        print(\"W3= \", W3)\n",
    "        print(\"b3= \", b3)\n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Entrenamiento Red Neuronal\n",
    "Se entrena la red neuronal utilizando el set de datos normalizado, como resultado se obtendra:\n",
    "1. Cada 100 epocas imprimira el valor de la función de costo que se esta optimizando\n",
    "2. Al finalizar la iteración por la cantidad de epocas imprimira el grafico de evolución de la función de costo\n",
    "3. Imprimira el valor de cada una de las matrices de pesos y bias de cada capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_x:  53\n",
      "n_y:  1\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Cost after epoch 0: 0.652608\n",
      "Cost after epoch 100: 0.003191\n",
      "Cost after epoch 200: 0.000361\n",
      "Cost after epoch 300: 0.000195\n",
      "Cost after epoch 400: 0.000039\n"
     ]
    }
   ],
   "source": [
    "#parameters = model(X_train_norm, Y_Train, X_train_norm, Y_Train)\n",
    "parameters = model(X_train_std, Y_Train, X_train_std, Y_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
